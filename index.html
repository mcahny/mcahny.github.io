<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.7.0">

  <meta name="author" content="Dahun Kim">
  <meta name="description" content="Ph.D Candidate">
  <link rel="alternate" hreflang="en-us" href="/">
  <meta name="theme-color" content="#2962ff">
   
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous"> 
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
  
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  <link rel="stylesheet" href="/css/academic.css">
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Dahun Kim">
  <link rel="manifest" href="/index.webmanifest">
  <!-- <link rel="icon" type="image/png" href="/images/icon_hu2065e2b3e3f9ec61858579cdb7515c4d_74858_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu2065e2b3e3f9ec61858579cdb7515c4d_74858_192x192_fill_lanczos_center_2.png"> -->

  <link rel="canonical" href="/">
  <meta property="twitter:card" content="summary">
  <meta property="og:site_name" content="Dahun Kim">
  <meta property="og:url" content="/">
  <meta property="og:title" content="Dahun Kim">
  <meta property="og:description" content="Assistant Professor"><meta property="og:image" content="img/map[gravatar:%!s(bool=false) shape:circle]">
  <meta property="twitter:image" content="img/map[gravatar:%!s(bool=false) shape:circle]"><meta property="og:locale" content="en-us">
  

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "WebSite",
  "potentialAction": {
    "@type": "SearchAction",
    "target": "/?q={search_term_string}",
    "query-input": "required name=search_term_string"
  },
  "url": "/"
}
</script>
  <title>Dahun Kim</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#navbar-main" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
      </div>

    </section>
  </div>
</aside>


<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Dahun Kim</a>
    </div>
    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>

    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Dahun Kim</a>
    </div>

    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content"> 
      <ul class="navbar-nav d-md-inline-flex">
        <li class="nav-item">
          <a class="nav-link " href="/#about" data-target="#about"><span>Home</span></a>
        </li>

        <li class="nav-item">
          <a class="nav-link " href="/#papers" data-target="#papers"><span>Publications</span></a>
        </li>

        <li class="nav-item">
          <a class="nav-link " href="/#awards" data-target="#awards"><span>Awards &amp; Honors</span></a>
        </li>


        <li class="nav-item">
          <a class="nav-link " href="/#activities" data-target="#activities"><span>Activities</span></a>
        </li>


      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>

    </ul>

  </div>
</nav>


<span class="js-widget-page d-none"></span>

  <section id="about" class="home-section wg-about   " style="padding: 30px 0 20px 0;" >
    <div class="container">

<div class="row">
  <div class="col-12 col-lg-4">
    <div id="profile">
      <img class="avatar avatar-circle" src="/authors/admin/profile.jpg" alt="Avatar">
      <div class="portrait-title">
        <h2>Dahun Kim</h2>
        <h3>Ph.D Candidate</h3>
        
        <h3>
          <a href="https://ee.kaist.ac.kr/" target="_blank" rel="noopener">
          <span>Electrical Engineering, KAIST</span>
          </a>
        </h3>
      </div>

      
      <td>
      <br>
      <a href="cv/dahun_cv_Oct_2021.pdf"><b>CV</b></a>
        | <a href="https://scholar.google.com/citations?user=mHpN1xoAAAAJ"><b>Google Scholar</b></a>
        | <a href="https://github.com/mcahny"><b>Github</b></a>
      <br>
      <br>
      </td>
     <!--  <ul class="network-icon" aria-hidden="true">    
        <li>
          <a href="https://scholar.google.com/citations?user=mHpN1xoAAAAJ&amp;hl=ko&amp;oi=ao" target="_blank" rel="noopener">
            <i class="ai ai-google-scholar big-icon"></i>
          </a>
        </li>  

        <li>
          <a href="https://github.com/mcahny" target="_blank" rel="noopener">
            <i class="fab fa-github big-icon"></i>
          </a>
        </li>

        <li>
          <a href="cv/dahun_cv_2020Mar.pdf" target="_blank" rel="noopener">
            <i class="fas fa-file-word big-icon"></i>
          </a>
        </li>

      </ul> -->
    </div>
  </div>
  <div class="col-12 col-lg-8">

    
<br>
<p>I am a Ph.D. student advised by Professor <a href="http://rcv.kaist.ac.kr">In So Kweon</a>, at <a href="https://ee.kaist.ac.kr/" target="_blank" rel="noopener">Electrical Engineering</a>, 
<a href="https://kaist.ac.kr/" target="_blank" rel="noopener">KAIST</a>. I interned at <a href="https://research.adobe.com/">Adobe</a> (San Jose, CA, 2019), <a href="https://ai.google/research/teams/brain/" target="_blank" rel="noopener">Google Brain</a> (Mountain View, CA, 2020), and <a href="https://ai.google/research/" target="_blank" rel="noopener">Google Research</a> (Virtual, 2021). I am a recepient of <a href="http://www.microsoft.com/en-us/research/lab/microsoft-research-asia/">Microsoft Research Asia Fellowship</a> (top 12 students in Asia-Pacific) and Global Ph.D Fellowship from NRF Korea.</p>

<p>My research interests lie in machine learning and computer vision.
Particularly, my research topics include spatio-temporal learning and video pixel labeling / generation tasks, and minimal human supervision (self- / weakly- supervised learning). </p>

    <div class="row">

      <div class="col-md-6">
        <h3>Contact</h3>
        <ul class="ul-contact fa-ul">
          <li>          
            <i class="fa-li fas fa-envelope"></i>
            <div class="description">
              <p class="course">mcahny [at] kaist.ac.kr</p>
              <p class="course">mcahny01 [at] gmail.com</p>
            </div>
          </li>
          <li>  
            <i class="fa-li fas fa-map-marker"></i>
            <div class="description">
              <p class="course">Bldg N1, Rm 211, 291 Daehak-ro, Yuseong-gu, Daejeon, Korea, 34141</p>
            </div> 
          </li>
          <!-- <li>  
            <i class="fa-li fas fa-phone-alt"></i>
            <div class="description">
              <p class="course">(&#43;82)-42-350-3579</p>
            </div> 
          </li>  -->         
        </ul>        
      </div>

      <div class="col-md-6">
        <h3>Education</h3>
        <ul class="ul-edu fa-ul">
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">MS in Electrical Engineering, 2018</p>
              <p class="institution">KAIST, Korea</p>
              <p class="institution">Thesis: "Reducing Human Supervision in Supervised Learning"</p>
              <p class="institution">Advisor: Prof. In So Kweon</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">BS in Electrical Engineering, 2016</p>
              <p class="institution">KAIST, Korea</p>
            </div>
          </li>

          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">Exchange Student Program, 2014</p>
              <p class="institution">KTH Royal Institute of Technology in Stockholm, Sweden</p>
            </div>
          </li>
        </ul>
      </div>
    </div>
  </div>
</div>

    </div>
  </section>



<section id="experience" class="home-section wg-blank   " style="padding: 10px 0 10px 0;" >
<div class="container">

<div class="row">
    <div class="col-lg-12">
    <h1>Research Experiences</h1>
      <!-- <h3 id="experience">Research Experiences</h3> -->
<ul>

<li> <div style="float:left"><b>Google Research</b>, LA, CA (virtual) </div><div style="float:right">May 2021 - Jan 2022</div> <br>
    Student Researcher (Part-time Intern) <br>
    Mentors: <a href="http://liangchiehchen.com/">Liang-Chieh Chen</a>
</li>

<li> <div style="float:left"><b>Google Brain</b>, MTV, CA (virtual) </div><div style="float:right">Jun 2020 - Nov 2020</div> <br>
    Research Intern, Brain Robotics Group, Vision Lab. <br>
    Mentors: <a href="https://weichengkuo.github.io/">Weicheng Kuo</a>, <a href="https://scholar.google.com/citations?user=_BPdgV0AAAAJ&hl=en">Tsung-Yi Lin</a>, and <a href="https://scholar.google.com/citations?user=nkmDOPgAAAAJ&hl=en">Anelia Anegelova</a> 
</li>

 <li> <div style="float:left"><b>Adobe Research</b>, San Jose, CA</div><div style="float:right">Jun 2019 - Sep 2019</div> <br>
    Research Intern, Deep Learning Group, Creative Intelligence Lab. <br>
    Mentor: <a href="http://joonyoung-cv.github.io">Joon-Young Lee</a>
</li>

<li> <div style="float:left"><b>KAIST</b>, Daejeon, Korea</div> <div style="float:right">Mar 2018 - Present</div> <br>
    Research Assistant, Robotics and Computer Vision Lab.
</li>

</ul>
    </div>
</div>
    </div>
  </section>

  <section id="papers" class="home-section wg-papers   " style="padding: 20px 0 20px 0;" >
    <div class="container">
      
<div class="row">
  
    <div class="col-lg-12">
      <h1>Publications</h1>
    </div>
    <div class="row">
        <ul class="ul-papers">
        
        <li>
            <div class="img">
              <img src="/papers/images/2022_wacv.png" class="img-responsive" alt="">
            </div>
          <div class="description">
            <p class="title">Tailor Me: An Editing Network for Fashion Attribute Shape Manipulation</p>
            <p class="authors">Youngjoong Kwon, Stefano Petrangeli, <b>Dahun Kim</b>, Haoliang Wang, Vishy Swaminathan, Henry Fuchs</p>
            <p class="venue">WACV 2022 <span style="font-weight:normal"></span></p>
            <p class="resources">
              [
                paper
              ]
            </p>
          </div>
        </li>
        <li>
            <div class="img">
              <img src="/papers/images/2021_bmvc.png" class="img-responsive" alt="">
            </div>
          <div class="description">
            <p class="title">Global Context and Geometric Priors for Effective Non-Local Self-Attention</p>
            <p class="authors">Sanghyun Woo, <b>Dahun Kim</b>, Joon-Young Lee, In So Kweon</p>
            <p class="venue">BMVC 2021 <span style="font-weight:bolder;color:#BB2222">Received Bronze Prize, 27th HumanTech Paper Award, Samsung Electronics Co., Ltd</span><span style="font-weight:normal"></span></p>
            <p class="resources">
              [
                paper
              ]
            </p>
          </div>
        </li>
        <li>
            <div class="img">
              <img src="/papers/images/2021_neurips_nhp.png" class="img-responsive" alt="">
            </div>
          <div class="description">
            <p class="title">Neural Human Performer: Learning Generalizable Radiance Fields for Human Performance Rendering</p>
            <p class="authors">Youngjoong Kwon, <b>Dahun Kim</b>, Duygu Ceylan, Henry Fuchs</p>
            <p class="venue">NeurIPS 2021 <span style="font-weight:bolder;color:#BB2222">Spotlight presentation</span> <span style="font-weight:normal">(Acceptance: < 3.0%)</span></p>
            <p class="resources">
              [
                <a href="https://arxiv.org/abs/2109.07448">paper</a> /
                code /
                <a href="https://youngjoongunc.github.io/nhp/">project</a>
              ]
            </p>
          </div>
        </li>
        <li>
            <div class="img">
              <img src="/papers/images/2021_preprint_oln.png" class="img-responsive" alt="">
            </div>
          <div class="description">
            <p class="title">Learning Open-World Object Proposals without Learning to Classify</p>
            <p class="authors"><b>Dahun Kim</b>, Tsung-Yi Lin, Anelia Angelova, In So Kweon, Weicheng Kuo</p>
            <p class="venue">Preprint 2021 <span style="font-weight:bolder;color:#BB2222">Invited paper talk at Open-World Segmentation (UVO) Workshop @ ICCV 2021 <br>
            Received Qualcomm Innovation Award 2021</span><span style="font-weight:normal"></span></p>
            <p class="resources">
              [
                <a href="https://arxiv.org/abs/2108.06753">paper</a> /
                <a href="https://github.com/mcahny/object_localization_network">code</a> / <a href="https://sites.google.com/view/unidentified-video-object/workshop-program">talk</a> 
              ]
            </p>
          </div>
        </li>
        <li>
            <div class="img">
              <img src="/papers/images/2021_tech_deeplab2.png" class="img-responsive" alt="">
            </div>
          <div class="description">
            <p class="title">DeepLab2: A TensorFlow Library for Deep Labeling</p>
            <p class="authors">Mark Weber, Huiyu Wang, Siyuan Qiao, Jun Xie, Maxwell D. Collins, Yukun Zhu, Liangzhe Yuan,<br/>
            &nbsp;&nbsp; <b>Dahun Kim</b>, Qihang Yu, Daniel Cremers, Laura Leal-Taixe, Alan L. Yuille, Florian Schroff, Hartwig Adam, Liang-Chieh Chen</p>
            <p class="venue">Technical report 2021 <span style="font-weight:bolder;color:#BB2222">Code contribution</span><span style="font-weight:normal"></span></p>

            <p class="resources">
              [
                <a href="https://arxiv.org/abs/2106.09748">paper</a> /
                <a href="https://github.com/google-research/deeplab2">code</a>
              ]
            </p>
          </div>
        </li>
        <li>
            <div class="img">
              <img src="/papers/images/2021_cvpr_vps.png" class="img-responsive" alt="">
            </div>
          <div class="description">
            <p class="title">Learning to Associate Every Segment for Video Panoptic Segmentation</p>
            <p class="authors">Sanghyun Woo, <b>Dahun Kim</b>, Joon-Young Lee, In So Kweon</p>
            <p class="venue">CVPR 2021 <span style="font-weight:normal"></span></p>
            <p class="resources">
              [
                <a href="https://arxiv.org/abs/2106.09453/">paper</a>
              ]
            </p>
          </div>
        </li>
        <li>
            <div class="img">
              <img src="/papers/images/2021_wacv_boundary.png" class="img-responsive" alt="">
            </div>
          <div class="description">
            <p class="title">The Devil is in the Boundary: Exploiting Boundary Representation for Basis-based Instance Segmentation</p>
            <p class="authors">Myungchul Kim, Sanghyun Woo, <b>Dahun Kim</b>, In So Kweon</p>
            <p class="venue">WACV 2021 <span style="font-weight:normal"></span></p>
            <p class="resources">
              [
                <a href="https://arxiv.org/abs/2011.13241">paper</a>
              ]
            </p>
          </div>
        </li>

        <li>
            <div class="img">
              <img src="/papers/images/2020_mm.png" class="img-responsive" alt="" >
            </div>
          <div class="description">
            <p class="title">Rotationally-Consistent Novel View Synthesis for Humans</p>
            <p class="authors">Youngjoong Kwon, Stefano Petrangeli, <b>Dahun Kim</b>, Haoliang Wang, Henry Fuchs, Vishy Swaminathan</p>
            <p class="venue">MM 2020 <span style="font-weight:normal">(Acceptance: 472/1698 ≈ 27.8%)</span></p>
            <p class="resources">
              [
                <a href="https://dl.acm.org/doi/10.1145/3394171.3413754">paper</a> /
                <a href="https://github.com/YoungJoongUNC/human_video_novel_view_synthesis">dataset</a>
              ]
            </p>
          </div>
        </li>

        <li>
            <div class="img">
              <img src="/papers/images/2020_bmvc.png" class="img-responsive" alt="">
            </div>
          <div class="description">
            <p class="title">Align-and-Attend Network for Globally and Locally Coherent Video Inpainting</p>
            <p class="authors">Sanghyun Woo, <b>Dahun Kim</b>, KwanYoung Park, Joon-Young Lee, In So Kweon</p>
            <p class="venue">BMVC 2020 <span style="font-weight:normal">(Acceptance: 195/670 ≈ 29.1%)</span></p>
            <p class="resources">
              [
                <a href="https://arxiv.org/abs/1905.13066">paper</a>
              ]
            </p>
          </div>
        </li>

        <li>
            <div class="img">
              <img src="/papers/images/2020.eccv.nvs.png" class="img-responsive" alt="">
            </div>
          <div class="description">
            <p class="title">Rotationally-Temporally Consistent Novel-View Synthesis of Human Performance Video</p>
            <p class="authors">Youngjoong Kwon, Stefano Petrangeli, <b>Dahun Kim</b>, Haoliang Wang, Eunbyung Park, Vishy Swaminathan, Henry Fuchs</p>
            <p class="venue">ECCV 2020  <span style="font-weight:bolder;color:#BB2222">Spotlight presentation</span> <span style="font-weight:normal">(Acceptance: 265/5025 ≈ 5.3%)</span></p>
            <p class="resources">
              [
                <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123490375.pdf">paper</a> /
                <a href="https://github.com/YoungJoongUNC/human_video_novel_view_synthesis">dataset</a> /
                <a href="https://github.com/YoungJoongUNC/human_video_novel_view_synthesis">code</a> 
              ]
            </p>
          </div>
        </li>

        <li>
            <div class="img">
              <img src="/papers/images/2020_cvpr_vps.png" class="img-responsive" alt="">
            </div>
          <div class="description">
            <p class="title">Video Panoptic Segmentation</p>
            <p class="authors"><b>Dahun Kim</b>, Sanghyun Woo, Joon-Young Lee, In So Kweon</p>
            <p class="venue">CVPR 2020  <span style="font-weight:bolder;color:#BB2222">Oral presentation</span> <span style="font-weight:normal">(Acceptance: 335/6656 ≈ 5.0%)</span></p>
            <p class="resources">
              [
                <a href="https://arxiv.org/abs/2006.11339">paper</a> /
                <a href="https://github.com/mcahny/vps">code</a> /
                <a href="https://sites.google.com/view/video-panoptic">project</a>
              ]
            </p>
          </div>
        </li>

        <li>
            <div class="img">
              <img src="/papers/images/2019_pami.png" class="img-responsive" alt="">
            </div>
          <div class="description">
            <p class="title">Recurrent Temporal Aggregation Framework for Deep Video Inpainting </p>
            <p class="authors"><b>Dahun Kim*</b>, Sanghyun Woo*, Joon-Young Lee, In So Kweon (* equal contribution)</p>
            <p class="venue">TPAMI 2020 <span style="font-weight:bolder;color:#BB2222">Received KAIST-Samsung Industry-University Cooperation Best Paper Award</span></p>
            <p class="resources">
              [
                <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8931251">paper</a> /
                <a href="https://github.com/mcahny/Deep-Video-Inpainting"> code </a> 
              ]
            </p>
          </div>
        </li>


        <li>
            <div class="img">
              <img src="/papers/images/2020_aaai_hidetell.jpeg" class="img-responsive" alt="">
            </div>
          <div class="description">
            <p class="title">Hide-and-Tell: Learning to Bridge Photo Streams for Visual Storytelling</p>
            <p class="authors">Yunjae Jung, <b>Dahun Kim</b>, Sanghyun Woo, Kyungsu Kim, Sungjin Kim, In So Kweon</p>
            <p class="venue">AAAI 2020 <span style="font-weight:normal">(Acceptance: 1591/7737 ≈ 20.6%)</span></p>
            <p class="resources">
              [
                <a href="https://arxiv.org/abs/2002.00774">paper</a>
              ]
            </p>
          </div>
        </li>

        <li>
            <div class="img">
              <img src="/papers/images/2019_cvpr_bvdnet.jpg" class="img-responsive" alt="">
            </div>
          
          <div class="description">
            <p class="title">Deep Blind Video Decaptioning by Temporal Aggregation and Recurrence</p>
            <p class="authors"><b>Dahun Kim*</b>, Sanghyun Woo*, Joon-Young Lee, In So Kweon (* equal contribution)</p>
            <p class="venue">CVPR 2019 <span style="font-weight:normal">(Acceptance: 1294/5160 ≈ 25.2%)</span></p>

            <span style="font-weight:bolder;color:#BB2222"> 1st place winner of ECCV 2018 Chalearn LAP Video De-Captioning Challenge</span> 
            <p class="resources">
              [
                <a href="https://arxiv.org/abs/1905.02949">paper</a>
                /<a href="https://github.com/mcahny/Deep-Video-Inpainting"> code </a>    
                /<a href="https://www.youtube.com/watch?v=8rcn5RGExO8&t=5s"> video</a>           
                /<a href="https://sites.google.com/view/bvdnet/"> project </a>                
              ]
            </p>
          </div>
        </li>

        <li>
            <div class="img">
              <img src="/papers/images/2019_cvpr_vinet.jpg" class="img-responsive" alt="">
            </div>
          
          <div class="description">
            <p class="title">Deep Video Inpainting</p>
            <p class="authors"><b>Dahun Kim*</b>, Sanghyun Woo*, Joon-Young Lee, In So Kweon (* equal contribution)</p>
            <p class="venue">CVPR 2019 <span style="font-weight:normal">(Acceptance: 1294/5160 ≈ 25.2%)</span></p>
            <p class="resources">
              [
                <a href="https://arxiv.org/abs/1905.01639">paper</a>
                /<a href="https://github.com/mcahny/Deep-Video-Inpainting"> code </a>    
                /<a href="https://www.youtube.com/watch?v=RtThGNTvkjY"> video</a>           
                /<a href="https://sites.google.com/view/deepvinet/"> project </a>                
              ]
            </p>
          </div>
        </li>

        <li>
            <div class="img">
              <img src="/papers/images/2019_aaai_cubic.png" class="img-responsive" alt="">
            </div>
          <div class="description">
            <p class="title">Self-Supervised Video Representation Learning with Space-Time Cubic Puzzles</p>
            <p class="authors"><b>Dahun Kim</b>, Donghyeon Cho, In So Kweon</p>
            <p class="venue">AAAI 2019 <span style="font-weight:bolder;color:#BB2222">Oral presentation</span> <span style="font-weight:normal">(Acceptance: 459/7095 ≈ 6.5%)</span></p>
            <p class="resources">
              [
                <a href="https://arxiv.org/abs/1811.09795"> paper </a>
              ]
            </p>
          </div>
        </li>


        <li>
            <div class="img">
              <img src="/papers/images/2019_aaai_csnet.png" class="img-responsive" alt="">
            </div>
          <div class="description">
            <p class="title">Discriminative Feature Learning for Unsupervised Video Summarization</p>
            <p class="authors">Yunjae Jung, Donghyeon Cho, <b>Dahun Kim</b>, Sanghyun Woo, In So Kweon</p>
            <p class="venue">AAAI 2019 <span style="font-weight:bolder;color:#BB2222">Oral presentation </span><span style="font-weight:normal">(Acceptance: 459/7095 ≈ 6.5%)</span><br>
            <span style="font-weight:bolder;color:#BB2222">Received Honorable Mention, 25th HumanTech Paper Award, Samsung Electronics Co., Ltd</span></p>
            <p class="resources">
              [
                <a href="https://arxiv.org/abs/1811.09791"> paper </a>
              ]
            </p>
          </div>
        </li>

        <li>
            <div class="img">
              <img src="/papers/images/2019_mm_retarget.jpg.JPG" class="img-responsive" alt="">
            </div>
          <div class="description">
            <p class="title">Video Retargeting: Trade-off between Content Preservation and Spatio-temporal Consistency</p>
            <p class="authors">Donghyeon Cho, Yunjae Jung, Francois Rameau, <b>Dahun Kim</b>, Sanghyun Woo and In So Kweon</p>
            <p class="venue">MM 2019 <span style="font-weight:normal">(Acceptance: 252/936 ≈ 26.9%)</span></p>
            <p class="resources">
              [
                <a href="https://dl.acm.org/citation.cfm?id=3350895"> paper </a>
              ]
            </p>
          </div>
        </li>

        <li>
            <div class="img">
              <img src="/papers/images/2019_mm_domain.JPG" class="img-responsive" alt="">
            </div>
          <div class="description">
            <p class="title">Preserving Semantic and Temporal Consistency for Unpaired Video-to-Video Translation</p>
            <p class="authors">Kwanyong Park, Sanghyun Woo, <b>Dahun Kim</b>, Donghyeon Cho, In So Kweon</p>
            <p class="venue">MM 2019 <span style="font-weight:normal">(Acceptance: 252/936 ≈ 26.9%)</span></p>
            <p class="resources">
              [
                <a href="https://arxiv.org/abs/1908.07683"> paper </a>
              ]
            </p>
          </div>
        </li>

        <li>
            <div class="img">
              <img src="/papers/images/2018_nips.png" class="img-responsive" alt="">
            </div>
          <div class="description">
            <p class="title">LinkNet: Relational Embedding for Scene Graph</p>
            <p class="authors">Sanghyun Woo*, <b>Dahun Kim*</b>, Donghyeon Cho, In So Kweon (* equal contribution)</p>
            <p class="venue">NIPS 2018 <span style="font-weight:normal">(Acceptance: 1011/4856 ≈ 20.8%)</span></p>
            <p class="resources">
              [
                <a href="https://arxiv.org/abs/1811.06410"> paper </a>
              ]
            </p>
          </div>
        </li>

        <li>
            <div class="img">
              <img src="/papers/images/2018_wacv_teaser.jpg" class="img-responsive" alt="">
            </div>
          <div class="description">
            <p class="title">Learning Image Representations by Completing Damaged Jigsaw Puzzles</p>
            <p class="authors"><b>Dahun Kim</b>, Donghyeon Cho, Donggeun Yoo, In So Kweon</p>
            <p class="venue">WACV 2018 <span style="font-weight:bolder;color:#BB2222">Oral presentation</span></p>
            <p class="resources">
              [
                <a href="https://arxiv.org/abs/1802.01880"> paper </a>
              ]
            </p>
          </div>
        </li>


        <li>
            <div class="img">
              <img src="/papers/images/2017_iccv_tpl.png" class="img-responsive" alt="">
            </div>
          <div class="description">
            <p class="title">Two Phase Learning for Weakly Supervised Object Localization</p>
            <p class="authors"><b>Dahun Kim</b>, Donghyeon Cho, Donggeun Yoo, In So Kweon</p>
            <p class="venue">ICCV 2017 <span style="font-weight:normal">(Acceptance: 621/2143 ≈ 28.9%)</span></p>
            <p class="resources">
              [
                <a href="https://arxiv.org/abs/1708.02108"> paper </a>
              ]
            </p>
          </div>
        </li>
     
        </ul>      
    </div>  
</div>
    </div>
  </section>


<section id="awards" class="home-section wg-blank   " style="padding: 20px 0 20px 0;" >
    <div class="container">

<div class="row">  
    <div class="col-lg-12">
      <h1>Awards &amp; Honors</h1>      
      <!-- <h2 id="ms-students">MS students</h2> -->
<ul>
<li>Qualcomm Innovation Award ($4,000), 2021</li>
<li>Outstanding Reviewer Award, IEEE Conference on Computer Vision and Pattern Recognition, 2021</li>
<li>Bronze Prize, 27th HumanTech Paper Award, Samsung Electronics Co., Ltd. 2021 ($5,000)</li>
<li>Outstanding Reviewer Award, European Conference on Computer Vision, 2020</li>
<li>KAIST-Samsung Industry-University Cooperation Best Paper Award ($3,000), 2020</li>
<li>Microsoft Research Asia (MSRA) Ph.D. Fellowship 2019 Winner ($10,000)</li>
<li>Global Ph.D. Fellowship, National Research Foundation of Korea ($60,000 + 3-year full scholarship)</li>
<li>1st Place Award in ChaLearn LAP 2018 Inpainting Challenge Track2 - Video Decaptioning (ECCV 2018 challenge)</li>
<li>Honorable Mention, 25th HumanTech Paper Award, Samsung Electronics Co., Ltd. 2019 ($2,000)</li>
<li>International Computer Vision Summer School (ICVSS) 2018, Sicily, Italy</li>
</ul>
    </div>
</div>
    </div>
  </section>



<section id="activities" class="home-section wg-blank   " style="padding: 20px 0 20px 0;" >
    <div class="container">

<div class="row">  
    <div class="col-lg-12">
      <h1>Academic Activities</h1>      
      <h2 id="reviewer">Reviewer</h2>
<ul>:
<li>EuroGraphics 2021</li>
<li>ECCV 2020</li>
<li>CVPR 2020, 2021</li>
<li>AAAI 2020, 2021</li>
<li>ICCV 2019, 2021</li>
<li>NeurIPS 2020</li>
<li>ICLR 2021, 2022</li>
<li>ICML 2021</li>
<li>Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</li>
<li>Transactions on Neural Networks and Learning Systems (TNNLS)</li>
<li>Transactions on Image Processing (TIP)</li>

</ul>
    </div>
</div>
    </div>
  </section>
  
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script> 
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    <script>const code_highlighting = false;</script>
    <script>const isSiteThemeDark = false;</script>
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>

    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>

    <script src="/js/academic.min.a8d7005002cb4a052fd6d721e83df9ba.js"></script>


  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    
    .
    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
